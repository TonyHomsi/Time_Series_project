{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "329e0c15",
   "metadata": {},
   "source": [
    "Dataset: Rare Event Classification in Multivariate Time Series https://arxiv.org/abs/1809.10717 (please cite this article, if using the dataset)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177136b4",
   "metadata": {},
   "source": [
    "we used a Dense layer Autoencoder before that does not use the temporal features in the data. In this post, we will improve on our approach by building an LSTM Autoencoder.\n",
    "\n",
    "Here, we will learn:\n",
    "* data preparation steps for an LSTM model,\n",
    "* building and implementing LSTM autoencoder, and\n",
    "* using LSTM autoencoder for rare-event classification.\n",
    "\n",
    "#### Quick recap on LSTM:\n",
    "* LSTM is a type of Recurrent Neural Network (RNN). RNNs, in general, and LSTM, specifically, are used on sequential or time series data.\n",
    "* These models are capable of automatically extracting effect of past events.\n",
    "* LSTM are known for its ability to extract both long- and short- term effects of pasts event."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9a5fb3",
   "metadata": {},
   "source": [
    "### LSTM Autoencoder for Multivariate Data\n",
    "\n",
    "In our problem, we have a multivariate time-series data. A multivariate time-series data contains multiple variables observed over a period of time. We will build an LSTM autoencoder on this multivariate time-series to perform rare-event classification.\n",
    "\n",
    "* we build an autoencoder on the normal (negatively labeled) data,\n",
    "* use it to reconstruct a new sample,\n",
    "* if the reconstruction error is high, we label it as a sheet-break.\n",
    "\n",
    "LSTM requires few special data-preprocessing steps. In the following, we will give sufficient attention to these steps.\n",
    "Let’s get to the implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5837f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pylab import rcParams\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras.utils\n",
    "from tensorflow.keras import optimizers\n",
    "from keras import Sequential#, optimizers\n",
    "from keras.optimizers import adam_v2\n",
    "from keras.models import Model\n",
    "#from keras.utils import plot_model\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.layers import Dense, LSTM, RepeatVector, TimeDistributed\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve\n",
    "from sklearn.metrics import recall_score, classification_report, auc, roc_curve\n",
    "from sklearn.metrics import precision_recall_fscore_support, f1_score\n",
    "\n",
    "from numpy.random import seed\n",
    "seed(7)\n",
    "import tensorflow\n",
    "tensorflow.random.set_seed(11)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "SEED = 123 #used to help randomly select the data points\n",
    "DATA_SPLIT_PCT = 0.2\n",
    "\n",
    "rcParams['figure.figsize'] = 8, 6\n",
    "LABELS = [\"Normal\",\"Break\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18aebe62",
   "metadata": {},
   "source": [
    "### Data preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74a54f6",
   "metadata": {},
   "source": [
    "The data is taken from https://arxiv.org/abs/1809.10717."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e2cfd0",
   "metadata": {},
   "source": [
    "The input to LSTMs are 3-dimensional arrays created from the time-series data. This is an error prone step so we will look at the details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c891ec0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"processminer-rare-event-mts - data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcd480f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>y</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>...</th>\n",
       "      <th>x52</th>\n",
       "      <th>x53</th>\n",
       "      <th>x54</th>\n",
       "      <th>x55</th>\n",
       "      <th>x56</th>\n",
       "      <th>x57</th>\n",
       "      <th>x58</th>\n",
       "      <th>x59</th>\n",
       "      <th>x60</th>\n",
       "      <th>x61</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5/1/99 0:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.376665</td>\n",
       "      <td>-4.596435</td>\n",
       "      <td>-4.095756</td>\n",
       "      <td>13.497687</td>\n",
       "      <td>-0.118830</td>\n",
       "      <td>-20.669883</td>\n",
       "      <td>0.000732</td>\n",
       "      <td>-0.061114</td>\n",
       "      <td>...</td>\n",
       "      <td>10.091721</td>\n",
       "      <td>0.053279</td>\n",
       "      <td>-4.936434</td>\n",
       "      <td>-24.590146</td>\n",
       "      <td>18.515436</td>\n",
       "      <td>3.473400</td>\n",
       "      <td>0.033444</td>\n",
       "      <td>0.953219</td>\n",
       "      <td>0.006076</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5/1/99 0:02</td>\n",
       "      <td>0</td>\n",
       "      <td>0.475720</td>\n",
       "      <td>-4.542502</td>\n",
       "      <td>-4.018359</td>\n",
       "      <td>16.230659</td>\n",
       "      <td>-0.128733</td>\n",
       "      <td>-18.758079</td>\n",
       "      <td>0.000732</td>\n",
       "      <td>-0.061114</td>\n",
       "      <td>...</td>\n",
       "      <td>10.095871</td>\n",
       "      <td>0.062801</td>\n",
       "      <td>-4.937179</td>\n",
       "      <td>-32.413266</td>\n",
       "      <td>22.760065</td>\n",
       "      <td>2.682933</td>\n",
       "      <td>0.033536</td>\n",
       "      <td>1.090502</td>\n",
       "      <td>0.006083</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5/1/99 0:04</td>\n",
       "      <td>0</td>\n",
       "      <td>0.363848</td>\n",
       "      <td>-4.681394</td>\n",
       "      <td>-4.353147</td>\n",
       "      <td>14.127997</td>\n",
       "      <td>-0.138636</td>\n",
       "      <td>-17.836632</td>\n",
       "      <td>0.010803</td>\n",
       "      <td>-0.061114</td>\n",
       "      <td>...</td>\n",
       "      <td>10.100265</td>\n",
       "      <td>0.072322</td>\n",
       "      <td>-4.937924</td>\n",
       "      <td>-34.183774</td>\n",
       "      <td>27.004663</td>\n",
       "      <td>3.537487</td>\n",
       "      <td>0.033629</td>\n",
       "      <td>1.840540</td>\n",
       "      <td>0.006090</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5/1/99 0:06</td>\n",
       "      <td>0</td>\n",
       "      <td>0.301590</td>\n",
       "      <td>-4.758934</td>\n",
       "      <td>-4.023612</td>\n",
       "      <td>13.161566</td>\n",
       "      <td>-0.148142</td>\n",
       "      <td>-18.517601</td>\n",
       "      <td>0.002075</td>\n",
       "      <td>-0.061114</td>\n",
       "      <td>...</td>\n",
       "      <td>10.104660</td>\n",
       "      <td>0.081600</td>\n",
       "      <td>-4.938669</td>\n",
       "      <td>-35.954281</td>\n",
       "      <td>21.672449</td>\n",
       "      <td>3.986095</td>\n",
       "      <td>0.033721</td>\n",
       "      <td>2.554880</td>\n",
       "      <td>0.006097</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5/1/99 0:08</td>\n",
       "      <td>0</td>\n",
       "      <td>0.265578</td>\n",
       "      <td>-4.749928</td>\n",
       "      <td>-4.333150</td>\n",
       "      <td>15.267340</td>\n",
       "      <td>-0.155314</td>\n",
       "      <td>-17.505913</td>\n",
       "      <td>0.000732</td>\n",
       "      <td>-0.061114</td>\n",
       "      <td>...</td>\n",
       "      <td>10.109054</td>\n",
       "      <td>0.091121</td>\n",
       "      <td>-4.939414</td>\n",
       "      <td>-37.724789</td>\n",
       "      <td>21.907251</td>\n",
       "      <td>3.601573</td>\n",
       "      <td>0.033777</td>\n",
       "      <td>1.410494</td>\n",
       "      <td>0.006105</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          time  y        x1        x2        x3         x4        x5  \\\n",
       "0  5/1/99 0:00  0  0.376665 -4.596435 -4.095756  13.497687 -0.118830   \n",
       "1  5/1/99 0:02  0  0.475720 -4.542502 -4.018359  16.230659 -0.128733   \n",
       "2  5/1/99 0:04  0  0.363848 -4.681394 -4.353147  14.127997 -0.138636   \n",
       "3  5/1/99 0:06  0  0.301590 -4.758934 -4.023612  13.161566 -0.148142   \n",
       "4  5/1/99 0:08  0  0.265578 -4.749928 -4.333150  15.267340 -0.155314   \n",
       "\n",
       "          x6        x7        x8  ...        x52       x53       x54  \\\n",
       "0 -20.669883  0.000732 -0.061114  ...  10.091721  0.053279 -4.936434   \n",
       "1 -18.758079  0.000732 -0.061114  ...  10.095871  0.062801 -4.937179   \n",
       "2 -17.836632  0.010803 -0.061114  ...  10.100265  0.072322 -4.937924   \n",
       "3 -18.517601  0.002075 -0.061114  ...  10.104660  0.081600 -4.938669   \n",
       "4 -17.505913  0.000732 -0.061114  ...  10.109054  0.091121 -4.939414   \n",
       "\n",
       "         x55        x56       x57       x58       x59       x60  x61  \n",
       "0 -24.590146  18.515436  3.473400  0.033444  0.953219  0.006076    0  \n",
       "1 -32.413266  22.760065  2.682933  0.033536  1.090502  0.006083    0  \n",
       "2 -34.183774  27.004663  3.537487  0.033629  1.840540  0.006090    0  \n",
       "3 -35.954281  21.672449  3.986095  0.033721  2.554880  0.006097    0  \n",
       "4 -37.724789  21.907251  3.601573  0.033777  1.410494  0.006105    0  \n",
       "\n",
       "[5 rows x 63 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5446d0f",
   "metadata": {},
   "source": [
    "The objective of this rare-event problem is to predict a sheet-break before it occurs. We will try to predict the break 4 minutes in advance. \n",
    "\n",
    "To build this model, we will shift the labels 2 rows up (which corresponds to 4 minutes). We can do this as df.y=df.y.shift(-2). However, in this problem we would want to do the shifting as: if row n is positively labeled,\n",
    "Make row (n-2) and (n-1) equal to 1. This will help the classifier learn up to 4 minute ahead prediction.\n",
    "\n",
    "Delete row n. Because we do not want the classifier to learn predicting a break when it has happened.\n",
    "We will develop the following UDF for this curve shifting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6b80401",
   "metadata": {},
   "outputs": [],
   "source": [
    "sign = lambda x: (1, -1)[x < 0]\n",
    "\n",
    "def curve_shift(df, shift_by):\n",
    "    '''\n",
    "    This function will shift the binary labels in a dataframe.\n",
    "    The curve shift will be with respect to the 1s. \n",
    "    For example, if shift is -2, the following process\n",
    "    will happen: if row n is labeled as 1, then\n",
    "    - Make row (n+shift_by):(n+shift_by-1) = 1.\n",
    "    - Remove row n.\n",
    "    i.e. the labels will be shifted up to 2 rows up.\n",
    "    \n",
    "    Inputs:\n",
    "    df       A pandas dataframe with a binary labeled column. \n",
    "             This labeled column should be named as 'y'.\n",
    "    shift_by An integer denoting the number of rows to shift.\n",
    "    \n",
    "    Output\n",
    "    df       A dataframe with the binary labels shifted by shift.\n",
    "    '''\n",
    "\n",
    "    vector = df['y'].copy()\n",
    "    for s in range(abs(shift_by)):\n",
    "        tmp = vector.shift(sign(shift_by))\n",
    "        tmp = tmp.fillna(0)\n",
    "        vector += tmp\n",
    "    labelcol = 'y'\n",
    "    # Add vector to the df\n",
    "    df.insert(loc=0, column=labelcol+'tmp', value=vector)\n",
    "    # Remove the rows with labelcol == 1.\n",
    "    df = df.drop(df[df[labelcol] == 1].index)\n",
    "    # Drop labelcol and rename the tmp col as labelcol\n",
    "    df = df.drop(labelcol, axis=1)\n",
    "    df = df.rename(columns={labelcol+'tmp': labelcol})\n",
    "    # Make the labelcol binary\n",
    "    df.loc[df[labelcol] > 0, labelcol] = 1\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1a5b012",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before shifting\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>y</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>5/1/99 8:32</td>\n",
       "      <td>0</td>\n",
       "      <td>1.016235</td>\n",
       "      <td>-4.058394</td>\n",
       "      <td>-1.097158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>5/1/99 8:34</td>\n",
       "      <td>0</td>\n",
       "      <td>1.005602</td>\n",
       "      <td>-3.876199</td>\n",
       "      <td>-1.074373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>5/1/99 8:36</td>\n",
       "      <td>0</td>\n",
       "      <td>0.933933</td>\n",
       "      <td>-3.868467</td>\n",
       "      <td>-1.249954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>5/1/99 8:38</td>\n",
       "      <td>1</td>\n",
       "      <td>0.892311</td>\n",
       "      <td>-13.332664</td>\n",
       "      <td>-10.006578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>5/1/99 10:50</td>\n",
       "      <td>0</td>\n",
       "      <td>0.020062</td>\n",
       "      <td>-3.987897</td>\n",
       "      <td>-1.248529</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             time  y        x1         x2         x3\n",
       "256   5/1/99 8:32  0  1.016235  -4.058394  -1.097158\n",
       "257   5/1/99 8:34  0  1.005602  -3.876199  -1.074373\n",
       "258   5/1/99 8:36  0  0.933933  -3.868467  -1.249954\n",
       "259   5/1/99 8:38  1  0.892311 -13.332664 -10.006578\n",
       "260  5/1/99 10:50  0  0.020062  -3.987897  -1.248529"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After shifting\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>time</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5/1/99 8:30</td>\n",
       "      <td>0.997107</td>\n",
       "      <td>-3.865720</td>\n",
       "      <td>-1.133779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5/1/99 8:32</td>\n",
       "      <td>1.016235</td>\n",
       "      <td>-4.058394</td>\n",
       "      <td>-1.097158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5/1/99 8:34</td>\n",
       "      <td>1.005602</td>\n",
       "      <td>-3.876199</td>\n",
       "      <td>-1.074373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5/1/99 8:36</td>\n",
       "      <td>0.933933</td>\n",
       "      <td>-3.868467</td>\n",
       "      <td>-1.249954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5/1/99 10:50</td>\n",
       "      <td>0.020062</td>\n",
       "      <td>-3.987897</td>\n",
       "      <td>-1.248529</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       y          time        x1        x2        x3\n",
       "255  0.0   5/1/99 8:30  0.997107 -3.865720 -1.133779\n",
       "256  0.0   5/1/99 8:32  1.016235 -4.058394 -1.097158\n",
       "257  1.0   5/1/99 8:34  1.005602 -3.876199 -1.074373\n",
       "258  1.0   5/1/99 8:36  0.933933 -3.868467 -1.249954\n",
       "260  0.0  5/1/99 10:50  0.020062 -3.987897 -1.248529"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "Shift the data by 2 units, equal to 4 minutes.\n",
    "\n",
    "Test: Testing whether the shift happened correctly.\n",
    "'''\n",
    "print('Before shifting')  # Positive labeled rows before shifting.\n",
    "one_indexes = df.index[df['y'] == 1]\n",
    "display(df.iloc[(one_indexes[0]-3):(one_indexes[0]+2), 0:5].head(n=5))\n",
    "\n",
    "# Shift the response column y by 2 rows to do a 4-min ahead prediction.\n",
    "df = curve_shift(df, shift_by = -2)\n",
    "\n",
    "print('After shifting')  # Validating if the shift happened correctly.\n",
    "display(df.iloc[(one_indexes[0]-4):(one_indexes[0]+1), 0:5].head(n=5))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fb860a",
   "metadata": {},
   "source": [
    "If we note here, we moved the positive label at 5/1/99 8:38 to n-1 and n-2 timestamps, and dropped row n. Also, there is a time difference of more than 2 minutes between a break row and the next row. This is because, when a break occurs, the machine stays in the break status for a while. During this time, we have y = 1 for consecutive rows. In the provided data, these consecutive break rows are deleted to prevent the classifier from learning to predict a break after it has already happened.  Refer https://arxiv.org/abs/1809.10717 for details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636a26b2",
   "metadata": {},
   "source": [
    "Before moving forward, we will drop the time, and also the categorical columns for simplicity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c901ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove time column, and the categorical columns\n",
    "df = df.drop(['time', 'x28', 'x61'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69736190",
   "metadata": {},
   "source": [
    "Now, we divide the data into train, valid, and test sets. Then we will take the subset of data with only 0s to train the autoencoder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4445d0",
   "metadata": {},
   "source": [
    "## Prepare data for LSTM models\n",
    "\n",
    "LSTM is a bit more demanding than other models. Significant amount of time and attention goes in preparing the data that fits an LSTM.\n",
    "\n",
    "First, we will create the 3-dimensional arrays of shape: (samples x timesteps x features). \n",
    "* Samples mean the number of data points. \n",
    "* Timesteps is the number of time steps we look back at any time t to make a prediction. This is also referred to as lookback period. \n",
    "* The features is the number of features the data has, in other words, the number of predictors in a multivariate data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66568a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_X = df.loc[:, df.columns != 'y'].values  # converts the df to a numpy array\n",
    "input_y = df['y'].values\n",
    "\n",
    "n_features = input_X.shape[1]  # number of feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145065b6",
   "metadata": {},
   "source": [
    "The input_X here is a 2-dimensional array of size samples x features. We want to be able to transform such a 2D array into a 3D array of size: samples x lookback x features. For that we develop the funtion below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88f3ec0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def temporalize(X, y, lookback):\n",
    "    '''\n",
    "    Inputs\n",
    "    X         A 2D numpy array ordered by time of shape: \n",
    "              (n_observations x n_features)\n",
    "    y         A 1D numpy array with indexes aligned with \n",
    "              X, i.e. y[i] should correspond to X[i]. \n",
    "              Shape: n_observations.\n",
    "    lookback  The window size to look back in the past \n",
    "              records. Shape: a scalar.\n",
    "\n",
    "    Output\n",
    "    output_X  A 3D numpy array of shape: \n",
    "              ((n_observations-lookback-1) x lookback x \n",
    "              n_features)\n",
    "    output_y  A 1D array of shape: \n",
    "              (n_observations-lookback-1), aligned with X.\n",
    "    '''\n",
    "    output_X = []\n",
    "    output_y = []\n",
    "    for i in range(len(X) - lookback - 1):\n",
    "        t = []\n",
    "        for j in range(1, lookback + 1):\n",
    "            # Gather the past records upto the lookback period\n",
    "            t.append(X[[(i + j + 1)], :])\n",
    "        output_X.append(t)\n",
    "        output_y.append(y[i + lookback + 1])\n",
    "    return np.squeeze(np.array(output_X)), np.array(output_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754b13af",
   "metadata": {},
   "source": [
    "In LSTM, to make prediction at any time t, we will look at data from (t-lookback):t. In the following, we have an example to show how the input data are transformed with the temporalize function with lookback=5. For the modeling, we may use a longer lookback.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6a29003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First instance of y = 1 in the original data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>...</th>\n",
       "      <th>x51</th>\n",
       "      <th>x52</th>\n",
       "      <th>x53</th>\n",
       "      <th>x54</th>\n",
       "      <th>x55</th>\n",
       "      <th>x56</th>\n",
       "      <th>x57</th>\n",
       "      <th>x58</th>\n",
       "      <th>x59</th>\n",
       "      <th>x60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.987078</td>\n",
       "      <td>-4.025989</td>\n",
       "      <td>-1.210205</td>\n",
       "      <td>0.899603</td>\n",
       "      <td>0.450338</td>\n",
       "      <td>14.098854</td>\n",
       "      <td>0.000732</td>\n",
       "      <td>-0.051043</td>\n",
       "      <td>-0.059966</td>\n",
       "      <td>...</td>\n",
       "      <td>29.984624</td>\n",
       "      <td>11.248703</td>\n",
       "      <td>-0.752385</td>\n",
       "      <td>-5.014893</td>\n",
       "      <td>-67.454037</td>\n",
       "      <td>66.232568</td>\n",
       "      <td>4.114269</td>\n",
       "      <td>0.033726</td>\n",
       "      <td>4.845087</td>\n",
       "      <td>0.007776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.921726</td>\n",
       "      <td>-3.728572</td>\n",
       "      <td>-1.230373</td>\n",
       "      <td>-1.598718</td>\n",
       "      <td>0.227178</td>\n",
       "      <td>14.594612</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>-0.051043</td>\n",
       "      <td>-0.040129</td>\n",
       "      <td>...</td>\n",
       "      <td>29.984624</td>\n",
       "      <td>11.253342</td>\n",
       "      <td>-0.752385</td>\n",
       "      <td>-5.014987</td>\n",
       "      <td>-58.029477</td>\n",
       "      <td>66.310022</td>\n",
       "      <td>3.537487</td>\n",
       "      <td>0.032518</td>\n",
       "      <td>4.969500</td>\n",
       "      <td>0.007760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.975947</td>\n",
       "      <td>-3.913736</td>\n",
       "      <td>-1.304682</td>\n",
       "      <td>0.561987</td>\n",
       "      <td>0.004034</td>\n",
       "      <td>14.630532</td>\n",
       "      <td>0.000732</td>\n",
       "      <td>-0.051043</td>\n",
       "      <td>-0.040129</td>\n",
       "      <td>...</td>\n",
       "      <td>29.984624</td>\n",
       "      <td>11.257736</td>\n",
       "      <td>-0.752385</td>\n",
       "      <td>-5.015081</td>\n",
       "      <td>-61.783749</td>\n",
       "      <td>71.917352</td>\n",
       "      <td>3.473400</td>\n",
       "      <td>0.031310</td>\n",
       "      <td>2.981432</td>\n",
       "      <td>0.007743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.997107</td>\n",
       "      <td>-3.865720</td>\n",
       "      <td>-1.133779</td>\n",
       "      <td>0.377295</td>\n",
       "      <td>-0.219126</td>\n",
       "      <td>14.666420</td>\n",
       "      <td>0.000732</td>\n",
       "      <td>-0.061114</td>\n",
       "      <td>-0.040129</td>\n",
       "      <td>...</td>\n",
       "      <td>29.984624</td>\n",
       "      <td>11.262375</td>\n",
       "      <td>-0.752385</td>\n",
       "      <td>-5.015176</td>\n",
       "      <td>-70.151791</td>\n",
       "      <td>73.876977</td>\n",
       "      <td>3.473400</td>\n",
       "      <td>0.030776</td>\n",
       "      <td>2.563593</td>\n",
       "      <td>0.007727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.016235</td>\n",
       "      <td>-4.058394</td>\n",
       "      <td>-1.097158</td>\n",
       "      <td>2.327307</td>\n",
       "      <td>-0.442286</td>\n",
       "      <td>14.702309</td>\n",
       "      <td>0.000732</td>\n",
       "      <td>-0.061114</td>\n",
       "      <td>-0.040129</td>\n",
       "      <td>...</td>\n",
       "      <td>29.984624</td>\n",
       "      <td>11.267013</td>\n",
       "      <td>-0.752385</td>\n",
       "      <td>-5.015270</td>\n",
       "      <td>-60.884701</td>\n",
       "      <td>72.188928</td>\n",
       "      <td>4.114269</td>\n",
       "      <td>0.031186</td>\n",
       "      <td>2.982454</td>\n",
       "      <td>0.007711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.005602</td>\n",
       "      <td>-3.876199</td>\n",
       "      <td>-1.074373</td>\n",
       "      <td>0.844397</td>\n",
       "      <td>-0.553050</td>\n",
       "      <td>14.738228</td>\n",
       "      <td>0.000732</td>\n",
       "      <td>-0.061114</td>\n",
       "      <td>-0.030057</td>\n",
       "      <td>...</td>\n",
       "      <td>29.984624</td>\n",
       "      <td>11.271652</td>\n",
       "      <td>-0.752385</td>\n",
       "      <td>-5.015364</td>\n",
       "      <td>-69.553891</td>\n",
       "      <td>70.500879</td>\n",
       "      <td>4.050182</td>\n",
       "      <td>0.031596</td>\n",
       "      <td>3.746714</td>\n",
       "      <td>0.007695</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       y        x1        x2        x3        x4        x5         x6  \\\n",
       "252  0.0  0.987078 -4.025989 -1.210205  0.899603  0.450338  14.098854   \n",
       "253  0.0  0.921726 -3.728572 -1.230373 -1.598718  0.227178  14.594612   \n",
       "254  0.0  0.975947 -3.913736 -1.304682  0.561987  0.004034  14.630532   \n",
       "255  0.0  0.997107 -3.865720 -1.133779  0.377295 -0.219126  14.666420   \n",
       "256  0.0  1.016235 -4.058394 -1.097158  2.327307 -0.442286  14.702309   \n",
       "257  1.0  1.005602 -3.876199 -1.074373  0.844397 -0.553050  14.738228   \n",
       "\n",
       "           x7        x8        x9  ...        x51        x52       x53  \\\n",
       "252  0.000732 -0.051043 -0.059966  ...  29.984624  11.248703 -0.752385   \n",
       "253  0.000061 -0.051043 -0.040129  ...  29.984624  11.253342 -0.752385   \n",
       "254  0.000732 -0.051043 -0.040129  ...  29.984624  11.257736 -0.752385   \n",
       "255  0.000732 -0.061114 -0.040129  ...  29.984624  11.262375 -0.752385   \n",
       "256  0.000732 -0.061114 -0.040129  ...  29.984624  11.267013 -0.752385   \n",
       "257  0.000732 -0.061114 -0.030057  ...  29.984624  11.271652 -0.752385   \n",
       "\n",
       "          x54        x55        x56       x57       x58       x59       x60  \n",
       "252 -5.014893 -67.454037  66.232568  4.114269  0.033726  4.845087  0.007776  \n",
       "253 -5.014987 -58.029477  66.310022  3.537487  0.032518  4.969500  0.007760  \n",
       "254 -5.015081 -61.783749  71.917352  3.473400  0.031310  2.981432  0.007743  \n",
       "255 -5.015176 -70.151791  73.876977  3.473400  0.030776  2.563593  0.007727  \n",
       "256 -5.015270 -60.884701  72.188928  4.114269  0.031186  2.982454  0.007711  \n",
       "257 -5.015364 -69.553891  70.500879  4.050182  0.031596  3.746714  0.007695  \n",
       "\n",
       "[6 rows x 60 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the same instance of y = 1, we are keeping past 5 samples in the 3D predictor array, X.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.921726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3.728572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.230373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.598718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.227178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>70.500879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>4.050182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>0.031596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>3.746714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>0.007695</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>295 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0\n",
       "0     0.921726\n",
       "1    -3.728572\n",
       "2    -1.230373\n",
       "3    -1.598718\n",
       "4     0.227178\n",
       "..         ...\n",
       "290  70.500879\n",
       "291   4.050182\n",
       "292   0.031596\n",
       "293   3.746714\n",
       "294   0.007695\n",
       "\n",
       "[295 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "Test: The 3D tensors (arrays) for LSTM are forming correctly.\n",
    "'''\n",
    "print('First instance of y = 1 in the original data')\n",
    "display(df.iloc[(np.where(np.array(input_y) == 1)[0][0]-5):(np.where(np.array(input_y) == 1)[0][0]+1), ])\n",
    "\n",
    "lookback = 5  # Equivalent to 10 min of past data.\n",
    "# Temporalize the data\n",
    "X, y = temporalize(X = input_X, y = input_y, lookback = lookback)\n",
    "\n",
    "print('For the same instance of y = 1, we are keeping past 5 samples in the 3D predictor array, X.')\n",
    "display(pd.DataFrame(np.concatenate(X[np.where(np.array(y) == 1)[0][0]], axis=0 ))) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95cafd0b",
   "metadata": {},
   "source": [
    "The two tables are the same. This testifies that we are correctly taking 5 samples (= lookback), X(t):X(t-5) to predict y(t).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d108a51d",
   "metadata": {},
   "source": [
    "What we are looking for here is,\n",
    "\n",
    "* In the original data, y = 1 at row 257.\n",
    "* With lookback = 5 we want the LSTM to look at the 5 rows before row 257 (including itself).\n",
    "* In the 3D array, X, each 2D block at X[i,:,:] denotes the prediction data that corresponds to y[i] . To draw an analogy, in regression y[i] corresponds to a 1D vector X[i,:] ; in LSTM y[i] corresponds to a 2D array X[i,:,:] .\n",
    "* This 2D block X[i,:,:] should have the predictors at input_X[i,:] and the previous rows up to the given lookback .\n",
    "* As we can see in the output above, the X[i,:,:] block in the bottom is the same as the five past rows of y=1 shown on the top.\n",
    "* Similarly, this is applied for the entire data, for all y’s. The example here is shown for an instance of y=1 for easier visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605638cd",
   "metadata": {},
   "source": [
    "### Divide the data into train, valid, and test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f09e4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(np.array(X), np.array(y), test_size=DATA_SPLIT_PCT, random_state=SEED)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=DATA_SPLIT_PCT, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0fb85cc1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11691, 5, 59)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69820f20",
   "metadata": {},
   "source": [
    "For training the autoencoder, we will be using the X coming from only the negatively labeled data. Therefore, we separate the X corresponding to y = 0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "110d6f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_y0 = X_train[y_train==0]\n",
    "X_train_y1 = X_train[y_train==1]\n",
    "\n",
    "X_valid_y0 = X_valid[y_valid==0]\n",
    "X_valid_y1 = X_valid[y_valid==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54bea940",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11536, 5, 59)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_y0.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da68a532",
   "metadata": {},
   "source": [
    "#### Reshaping the data\n",
    "The tensors we have here are 4-dimensional. We will reshape them into the desired 3-dimensions corresponding to sample x lookback x features.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "321333c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], lookback, n_features)\n",
    "X_train_y0 = X_train_y0.reshape(X_train_y0.shape[0], lookback, n_features)\n",
    "X_train_y1 = X_train_y1.reshape(X_train_y1.shape[0], lookback, n_features)\n",
    "\n",
    "X_test = X_test.reshape(X_test.shape[0], lookback, n_features)\n",
    "\n",
    "X_valid = X_valid.reshape(X_valid.shape[0], lookback, n_features)\n",
    "X_valid_y0 = X_valid_y0.reshape(X_valid_y0.shape[0], lookback, n_features)\n",
    "X_valid_y1 = X_valid_y1.reshape(X_valid_y1.shape[0], lookback, n_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14235e16",
   "metadata": {},
   "source": [
    "### Standardization\n",
    "It is usually better to use a standardized data (transformed to Gaussian, mean 0 and variance 1) for autoencoders.\n",
    "\n",
    "**One common mistake is: we normalize the entire data and then split into train-test. This is not correct. Test data should be completely unseen to anything during the modeling. We should normalize the test data using the feature summary statistics computed from the training data. For normalization, these statistics are the mean and variance for each feature.**\n",
    "\n",
    "The same logic should be used for the validation set. This makes the model more stable for a test data.\n",
    "\n",
    "Standardizing this data is a bit tricky. This is because the X matrices are 3D, and we want the standardization to happen with respect to the original 2D data.\n",
    "\n",
    "To do this, we will require two UDFs.\n",
    "\n",
    "`flatten`: This function will re-create the original 2D array from which the 3D arrays were created. This function is the inverse of temporalize, meaning `X = flatten(temporalize(X))`.\n",
    "\n",
    "`scale`: This function will scale a 3D array that we created as inputs to the LSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "490459be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(X):\n",
    "    '''\n",
    "    Flatten a 3D array.\n",
    "    \n",
    "    Input\n",
    "    X            A 3D array for lstm, where the array is sample x timesteps x features.\n",
    "    \n",
    "    Output\n",
    "    flattened_X  A 2D array, sample x features.\n",
    "    '''\n",
    "    flattened_X = np.empty((X.shape[0], X.shape[2]))  # sample x features array.\n",
    "    for i in range(X.shape[0]):\n",
    "        flattened_X[i] = X[i, (X.shape[1]-1), :]\n",
    "    return(flattened_X)\n",
    "\n",
    "def scale(X, scaler):\n",
    "    '''\n",
    "    Scale 3D array.\n",
    "\n",
    "    Inputs\n",
    "    X            A 3D array for lstm, where the array is sample x timesteps x features.\n",
    "    scaler       A scaler object, e.g., sklearn.preprocessing.StandardScaler, sklearn.preprocessing.normalize\n",
    "    \n",
    "    Output\n",
    "    X            Scaled 3D array.\n",
    "    '''\n",
    "    for i in range(X.shape[0]):\n",
    "        X[i, :, :] = scaler.transform(X[i, :, :])\n",
    "        \n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5020d8c7",
   "metadata": {},
   "source": [
    "**Why didn’t we first normalize the original 2D data and then create the 3D arrays? Because, to do this we will: split the data into train and test, followed by their normalization. However, when we create the 3D arrays on the test data, we lose the initial rows of samples up till the lookback. Splitting into train-valid-test will cause this for both the validation and test sets.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268e72bb",
   "metadata": {},
   "source": [
    "We will fit a Standardization object from sklearn. This function standardizes the data to Normal(0, 1). Note that we require to flatten the X_train_y0 array to pass to the fit function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "24bd0822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a scaler using the training data.\n",
    "scaler = StandardScaler().fit(flatten(X_train_y0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "62853850",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_y0_scaled = scale(X_train_y0, scaler)\n",
    "X_train_y1_scaled = scale(X_train_y1, scaler)\n",
    "X_train_scaled = scale(X_train, scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b7baccc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "colwise mean [ 0. -0.  0.  0.  0. -0.  0.  0.  0.  0. -0. -0. -0. -0. -0.  0. -0. -0.\n",
      " -0. -0.  0.  0. -0. -0.  0.  0. -0.  0. -0.  0.  0.  0. -0. -0. -0.  0.\n",
      "  0.  0. -0.  0.  0.  0. -0. -0.  0.  0.  0.  0.  0.  0.  0. -0. -0.  0.\n",
      "  0. -0. -0.  0.  0.]\n",
      "colwise variance [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Test: Check if the scaling is correct.\n",
    "\n",
    "The test succeeds if all the column means \n",
    "and variances are 0 and 1, respectively, after\n",
    "flattening.\n",
    "'''\n",
    "a = flatten(X_train_y0_scaled)\n",
    "print('colwise mean', np.mean(a, axis=0).round(6))\n",
    "print('colwise variance', np.var(a, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae2e7d2",
   "metadata": {},
   "source": [
    "All the means and variances outputted above are 0 and 1, respectively. Therefore, the scaling is correct. We will now scale the validation and test sets. We will again use the scaler object on these sets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5cd9171",
   "metadata": {},
   "source": [
    "The test succeeded. Now we will scale the validation and test sets.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "751157d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid_scaled = scale(X_valid, scaler)\n",
    "X_valid_y0_scaled = scale(X_valid_y0, scaler)\n",
    "\n",
    "X_test_scaled = scale(X_test, scaler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7298f282",
   "metadata": {},
   "source": [
    "## LSTM Autoencoder training\n",
    "\n",
    "### Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e1a592",
   "metadata": {},
   "source": [
    "First we will initialize the Autoencoder architecture. We are building a simple autoencoder. More complex architectures and other configurations should be explored.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "80616735",
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps =  X_train_y0_scaled.shape[1] # equal to the lookback\n",
    "n_features =  X_train_y0_scaled.shape[2] # 59\n",
    "\n",
    "epochs = 200\n",
    "batch = 64\n",
    "lr = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ee6eccca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 5, 32)             11776     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 16)                3136      \n",
      "_________________________________________________________________\n",
      "repeat_vector (RepeatVector) (None, 5, 16)             0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 5, 16)             2112      \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 5, 32)             6272      \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 5, 59)             1947      \n",
      "=================================================================\n",
      "Total params: 25,243\n",
      "Trainable params: 25,243\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lstm_autoencoder = Sequential()\n",
    "# Encoder\n",
    "lstm_autoencoder.add(LSTM(32, activation='relu', input_shape=(timesteps, n_features), return_sequences=True))\n",
    "lstm_autoencoder.add(LSTM(16, activation='relu', return_sequences=False))\n",
    "lstm_autoencoder.add(RepeatVector(timesteps))\n",
    "# Decoder\n",
    "lstm_autoencoder.add(LSTM(16, activation='relu', return_sequences=True))\n",
    "lstm_autoencoder.add(LSTM(32, activation='relu', return_sequences=True))\n",
    "lstm_autoencoder.add(TimeDistributed(Dense(n_features)))\n",
    "\n",
    "lstm_autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8542b0",
   "metadata": {},
   "source": [
    "As a rule-of-thumb, look at the number of parameters. If not using any regularization, keep this less than the number of samples. If using regularization, depending on the degree of regularization you can let more parameters in the model that is greater than the sample size. For example, if using dropout with 0.5, you can have up to double the sample size (loosely speaking).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657b3b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "181/181 - 38s - loss: 0.7639 - accuracy: 0.0837 - val_loss: 0.5268 - val_accuracy: 0.1653\n",
      "Epoch 2/200\n",
      "181/181 - 14s - loss: 0.4392 - accuracy: 0.2092 - val_loss: 0.3643 - val_accuracy: 0.2853\n",
      "Epoch 3/200\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "adam = tf.keras.optimizers.Adam(\n",
    "    learning_rate=0.0001,\n",
    "    beta_1=0.9,\n",
    "    beta_2=0.999,\n",
    "    epsilon=1e-07,\n",
    "    amsgrad=False,\n",
    "    name=\"Adam\"\n",
    ")\n",
    "lstm_autoencoder.compile(metrics=['accuracy'],\n",
    "                    loss='mse',\n",
    "                    optimizer='adam')\n",
    "\n",
    "cp = ModelCheckpoint(filepath=\"lstm_autoencoder_classifier.h5\",\n",
    "                               save_best_only=True,\n",
    "                               verbose=0)\n",
    "\n",
    "tb = TensorBoard(log_dir='./logs',\n",
    "                histogram_freq=0,\n",
    "                write_graph=True,\n",
    "                write_images=True)\n",
    "\n",
    "lstm_autoencoder_history = lstm_autoencoder.fit(X_train_y0_scaled, X_train_y0_scaled, \n",
    "                                                epochs=epochs, \n",
    "                                                batch_size=batch, \n",
    "                                                validation_data=(X_valid_y0_scaled, X_valid_y0_scaled),\n",
    "                                                verbose=2).history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6a6857",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840fb197",
   "metadata": {},
   "source": [
    "In the following, we show how we can use an Autoencoder reconstruction error for the rare-event classification.\n",
    "As mentioned before, if the reconstruction error is high, we will classify it as a sheet-break. We will need to determine the threshold for this.\n",
    "We will use the validation set to identify the threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78d25a7",
   "metadata": {},
   "source": [
    "### ROC curve and AUC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453fc48a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu2",
   "language": "python",
   "name": "gpu2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
